{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "\bFastTracking.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozH_5HXDALLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime\n",
        "!pip install ttictoc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0Eq-X5AhEvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "from google.colab.patches import cv2_imshow\n",
        "import zipfile\n",
        "import io\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "import scipy.fft\n",
        "from scipy.linalg import dft\n",
        "from scipy.ndimage.interpolation import shift\n",
        "import zipfile\n",
        "from scipy import misc, fftpack\n",
        "import math\n",
        "from skimage.feature import hog\n",
        "from skimage import data, exposure\n",
        "from ttictoc import  tic, toc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDehVFsslckG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "data = zipfile.ZipFile(\"/content/Liquor.zip\", 'r')\n",
        "data.extractall()\n",
        "data = zipfile.ZipFile(\"/content/FaceOcc2.zip\", 'r')\n",
        "data.extractall()\n",
        "data = zipfile.ZipFile(\"/content/Dog1.zip\", 'r')\n",
        "data.extractall()\n",
        "data = zipfile.ZipFile(\"/content/Girl.zip\", 'r')\n",
        "data.extractall()\n",
        "data = zipfile.ZipFile(\"/content/FaceOcc1.zip\", 'r')\n",
        "data.extractall()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkdGBx7fwdDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def videoInfor(video_path):\n",
        "  if video_path[-1] != '/':\n",
        "    video_path = video_path + '/'\n",
        "\n",
        "  gt_path = video_path + \"groundtruth_rect.txt\"\n",
        "\n",
        "  try:\n",
        "    ground_truth = np.loadtxt(gt_path,dtype=[('f0',int),('f1',int),('f2',int),('f3',int)])\n",
        "  except:\n",
        "    ground_truth = np.loadtxt(gt_path,delimiter=',',dtype=[('f0',int),('f1',int),('f2',int),('f3',int)])\n",
        "\n",
        "\n",
        "  #Initial position and targer size \n",
        "  target_sz = np.array([ground_truth[0][3],ground_truth[0][2]]) # HxW\n",
        "  #Center position\n",
        "  pos = np.array([ground_truth[0][1],ground_truth[0][0]]) + np.floor(target_sz/2)\n",
        "\n",
        "  temp = np.zeros((ground_truth.shape[0],2))\n",
        "\n",
        "  # #Store positions instead of boxes\n",
        "  # for i in range(ground_truth.shape[0]):\n",
        "  #   temp[i][0] = ground_truth[i][1] + ground_truth[i][3]/2 # y\n",
        "  #   temp[i][1] = ground_truth[i][0] + ground_truth[i][2]/2 # x\n",
        "  # ground_truth = temp\n",
        "\n",
        "  img_path = video_path + \"img\"\n",
        "  pictureSequences = os.listdir(img_path)\n",
        "\n",
        "  img_files = np.array([])\n",
        "\n",
        "  for i in sorted(pictureSequences):\n",
        "    img_files = np.append(img_files,i)\n",
        "\n",
        "  return (img_files,pos,target_sz,ground_truth,video_path)\n",
        "\n",
        "def calculateOR(gt_tl,gt_br,bb_tl,bb_br):\n",
        "  # 8 points\n",
        "  widthIntersection = np.maximum(0,np.minimum(gt_br[0],bb_br[0])-np.maximum(gt_tl[0],bb_tl[0]))\n",
        "  # print(widthIntersection)\n",
        "  heighIntersection = np.maximum(0,np.minimum(gt_br[1],bb_br[1])-np.maximum(gt_tl[1],bb_tl[1]))\n",
        "  # print(heighIntersection)\n",
        "  intersectionArea = widthIntersection*heighIntersection\n",
        "  groundTruthArea = (gt_br[0]-gt_tl[0])*(gt_br[1]-gt_tl[1])\n",
        "  bboxArea = (bb_br[0]-bb_tl[0])*(bb_br[1]-bb_tl[1])\n",
        "  return intersectionArea*100/(groundTruthArea+bboxArea-intersectionArea)\n",
        "\n",
        "def gaussian_shaped_labels(sigma,sz):\n",
        "  #CHECKED\n",
        "  cs,rs = np.meshgrid(np.arange(0,sz[1])-np.floor(sz[1]/2),np.arange(0,sz[0]) - np.floor(sz[0]/2))\n",
        "  cs = cs + 1\n",
        "  rs = rs + 1\n",
        "  labels = np.exp(-0.5*(rs**2 + cs**2)/sigma**2)\n",
        "  labels = np.roll(labels, int(-np.floor(sz[0]/2)+1),axis=0)\n",
        "  labels = np.roll(labels, int(-np.floor(sz[1]/2)+1),axis=1)\n",
        "  # plt.imshow(labels)\n",
        "  # print(labels)\n",
        "  if np.round(labels[0][0]) !=1:\n",
        "    print('LOI CMNR')\n",
        "  return labels\n",
        "\n",
        "def gaussian_correlation(xf,yf,sigma,features):\n",
        "  N = xf.shape[0]*xf.shape[1]\n",
        "  \n",
        "  xx = np.linalg.norm(xf.ravel(), ord=2)**2/N\n",
        "  yy = np.linalg.norm(yf.ravel(), ord=2)**2/N\n",
        "  \n",
        "  xyf = xf*np.conjugate(yf)\n",
        "  if features.features_type == 'hog':\n",
        "    xy = np.sum(np.real(np.fft.ifft2(xyf)),axis=2)\n",
        "  elif features.features_type == 'gray':\n",
        "    xy = np.real(np.fft.ifft2(xyf))\n",
        "  # print(xy)\n",
        "  sss = ((xx+yy -2*xy)/N)\n",
        "  \n",
        "  Kf = np.fft.fft2(np.exp(-1*sss/sigma**2))\n",
        "  # print(Kf)\n",
        "  \n",
        "  return Kf\n",
        "\n",
        "\n",
        "\n",
        "def get_subwindow(im,pos,sz):\n",
        "  # CHECKED\n",
        "  if np.isscalar(sz):\n",
        "    sz = np.array([sz, sz])\n",
        " \n",
        "  ys = np.floor(pos[0]) + np.arange(0,sz[0]) - np.floor((sz[0])/2) +1\n",
        "  xs = np.floor(pos[1]) + np.arange(0,sz[1]) - np.floor((sz[1])/2) +1 \n",
        "  \n",
        "  xs[xs<1] = 1\n",
        "  ys[ys<1] = 1\n",
        "  xs[xs>im.shape[1]] = im.shape[1]\n",
        "  ys[ys>im.shape[0]] = im.shape[0]\n",
        "  \n",
        "  out = np.zeros((ys.shape[0],xs.shape[0]))\n",
        " \n",
        "  for i,data_y in enumerate(ys):\n",
        "    for j,data_x in enumerate(xs):\n",
        "      temp =  im[int(data_y)-1][int(data_x)-1]\n",
        "      out[i][j] = temp\n",
        "  return out\n",
        "\n",
        "\n",
        "def tracker(video_path,img_files,pos,target_sz,padding,\n",
        "            kernel,lambda_reg,output_sigma_factor,interp_factor,\n",
        "            cell_size,features,gt):\n",
        "\n",
        "  resize_image = (np.sqrt(np.prod(target_sz)) >= 100)\n",
        "  if resize_image:\n",
        "    pos = np.floor(pos/2)\n",
        "    target_sz = np.floor(target_sz/2);\n",
        "    for i in range(gt.shape[0]):\n",
        "      for j in range(4):\n",
        "        gt[i][j] = gt[i][j]/2\n",
        "    \n",
        "\n",
        "  def resize_image_true(resize_image):\n",
        "    if resize_image:\n",
        "      sample = cv2.imread(video_path + \"img/0001.jpg\")\n",
        "      sample = cv2.resize(sample,(int(sample.shape[1]/2),int(sample.shape[0]/2)))\n",
        "      width,heigh,_ = sample.shape\n",
        "    else:\n",
        "      sample = cv2.imread(video_path + \"img/0001.jpg\")\n",
        "      width,heigh,_ = sample.shape\n",
        "    return width,heigh\n",
        "\n",
        "  # Recorded video\n",
        "  width, heigh = resize_image_true(resize_image)\n",
        "  # print(width,heigh)\n",
        "  res=(heigh,width) #video resolution\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'MP4V') #codec\n",
        "  video = cv2.VideoWriter('Tracking.mp4', fourcc, 20.0, res)\n",
        "\n",
        "  # window size, taking padding into account\n",
        "  window_sz = np.floor(target_sz*(1+padding))\n",
        "\n",
        "  # create regression labels, gaussian shaped, with a bandwidth\n",
        "\t# proportional to target size\n",
        "  output_sigma = np.sqrt(np.prod(target_sz)) * output_sigma_factor/cell_size\n",
        "  yf = np.fft.fft2(gaussian_shaped_labels(output_sigma, np.floor(window_sz / cell_size)))\n",
        "  \n",
        "  # store pre-computed cosine window \n",
        "  # CHECKED\n",
        "  OR = np.array([])\n",
        "  cos_window = np.hanning(yf.shape[0]).reshape(yf.shape[0],1)*np.hanning(yf.shape[1]).reshape(1,yf.shape[1])\n",
        "  time = 0\n",
        "  positions = np.zeros((img_files.shape[0],2)) #to calculate precision\n",
        "  for i,frame in enumerate(img_files):\n",
        "    #Load images\n",
        "    im = cv2.imread(video_path + \"img/\" + frame)\n",
        "\n",
        "    if im.shape[2] > 1:\n",
        "      im = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
        "    if resize_image:\n",
        "      im = cv2.resize(im,(int(im.shape[1]/2),int(im.shape[0]/2)))\n",
        "    \n",
        "    # tic()\n",
        "    tic()\n",
        "    if i > 0:\n",
        "      #Get the subwindow for detection at the postion from the last frame \n",
        "      #and convert to Fdomain \n",
        "      \n",
        "      patch = get_subwindow(im, pos, window_sz)\n",
        "      \n",
        "      zf = np.fft.fft2(get_features(patch,cos_window,features))\n",
        "      \n",
        "      kzf = gaussian_correlation(zf,model_xf,kernel.sigma,features)\n",
        "\n",
        "      response = np.real(np.fft.ifft2(np.multiply(model_alphaf,kzf)))\n",
        "\n",
        "      temp = np.argwhere(response == (np.max(response[:])))\n",
        "      \n",
        "      vert_delta = temp[0][0]\n",
        "      horiz_delta = temp[0][1]\n",
        "      \n",
        "      if vert_delta > zf.shape[0]/2:\n",
        "        vert_delta = vert_delta - zf.shape[0]\n",
        "      if horiz_delta > zf.shape[1]/2:\n",
        "      \thoriz_delta = horiz_delta - zf.shape[1]\n",
        "\n",
        "      pos = pos + cell_size*np.array([vert_delta,horiz_delta])\n",
        "      \n",
        "    patch = get_subwindow(im, pos, window_sz)\n",
        "  \n",
        "    xf = np.fft.fft2(get_features(patch,cos_window,features))\n",
        "    kf = gaussian_correlation(xf, xf, kernel.sigma,features)\n",
        "\n",
        "    alphaf = np.divide(yf,(kf+lambda_reg))\n",
        "\n",
        "    if i == 0:\n",
        "      model_alphaf = alphaf\n",
        "      model_xf = xf\n",
        "    else:\n",
        "      model_alphaf = (1-interp_factor)*model_alphaf + interp_factor*alphaf\n",
        "      model_xf = (1-interp_factor)*model_xf + interp_factor*xf\n",
        "   \n",
        "    positions[i,:] = pos\n",
        "    time = time + toc()\n",
        "\n",
        "    t_left  = pos[::-1]- np.round(target_sz[::-1]/2)\n",
        "    b_right = pos[::-1]+ np.round(target_sz[::-1]/2)\n",
        "    \n",
        "    im = cv2.imread(video_path + \"img/\" + frame)\n",
        "    if resize_image:\n",
        "      im = cv2.resize(im,(int(im.shape[1]/2),int(im.shape[0]/2)))\n",
        "\n",
        "    boxedImage = cv2.rectangle(im,(int(t_left[0]),int(t_left[1])),(int(b_right[0]),int(b_right[1])),(0,255,0),1)\n",
        "    boxedImage = cv2.putText(boxedImage,'Fast Tracking',(int(t_left[0]),int(t_left[1]) - 5), cv2.FONT_HERSHEY_SIMPLEX , 0.2, (36,255,12), 1)\n",
        "    boxedImage = cv2.rectangle(boxedImage,(int(gt[i][0]),int(gt[i][1])),(int(gt[i][0]) + int(gt[i][2]),int(gt[i][1])+int(gt[i][3])),(0,255,255),1)\n",
        "    boxedImage = cv2.putText(boxedImage,'Ground Truth',(int(gt[i][0]),int(gt[i][1]) - 2), cv2.FONT_HERSHEY_SIMPLEX , 0.2, (0,255,122), 1)\n",
        "    boxedImage = cv2.putText(boxedImage, str(i),(10,30), cv2.FONT_HERSHEY_SIMPLEX , 1, (0,255,122), 1)\n",
        "    matchingRatio = calculateOR((gt[i][0],gt[i][1]),(gt[i][0] + gt[i][2],gt[i][1]+gt[i][3]),(int(t_left[0]),int(t_left[1])),(int(b_right[0]),int(b_right[1])))\n",
        "    OR = np.append(OR,matchingRatio)\n",
        "    # cv2_imshow(boxedImage)\n",
        "    video.write(boxedImage)\n",
        "    if i == gt.size-1:\n",
        "      break\n",
        "    # if i == 10:\n",
        "    #   break\n",
        "    if i == 1:\n",
        "      cv2_imshow(boxedImage)\n",
        "    if i == 100:\n",
        "      cv2_imshow(boxedImage)  \n",
        "  \n",
        "  testSeq = 'Girl'\n",
        "\n",
        "  # print(np.mean(OR))\n",
        "  plt.figure\n",
        "  plt.plot(range(0,OR.shape[0]),OR,'-',label=testSeq)\n",
        "  plt.plot(range(0,OR.shape[0]),np.ones(OR.shape[0])*np.mean(OR),'-',label=\"Average\")\n",
        "  plt.title(\"Tracking Accuracy of Video Sequences \" + testSeq)\n",
        "  plt.xlabel(\"Frames\")\n",
        "  plt.ylabel(\"Overlap Ratio\")\n",
        "  plt.legend(loc=\"upper right\")\n",
        "\n",
        "  video.release()\n",
        "  \n",
        "  FPS = OR.shape[0]/time\n",
        "  print('Computation Time:' + str(time))\n",
        "  print('FPS :' + str(FPS)) \n",
        "\n",
        "  if resize_image:\n",
        "    positions = positions*2\n",
        "\n",
        "\n",
        "def get_features(im,cos_window,features):\n",
        "  if features.features_type == 'hog':\n",
        "    x = hog(im,orientations=31,pixels_per_cell=(4,4),cells_per_block=(1,1),feature_vector=False)\n",
        "    x = x[:,:,0,0,:]\n",
        "    # print(im.shape)\n",
        "    # print(x.shape)\n",
        "  else:\n",
        "    x = np.double(im)/255\n",
        "    x = x - np.mean(x[:])  \n",
        "  \n",
        "\n",
        "  if cos_window.size != 0:\n",
        "    if features == 'gray':\n",
        "      x = x*cos_window\n",
        "    elif features == 'hog':\n",
        "      x = np.multiply(x,cos_window)\n",
        "\t\n",
        "  return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwt0i6nMln_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initial Parameters \n",
        "padding = 1.5  \n",
        "lambda_reg = 1e-4  \n",
        "output_sigma_factor = 0.1;\n",
        "\n",
        "class kernel_struct: \n",
        "  #Class kernel\n",
        "  def __init__(self,sigma,kernel_type):\n",
        "    self.sigma = sigma\n",
        "    self.kernel_type = kernel_type\n",
        "    \n",
        "class features_struct:\n",
        "  def __init__(self,features_type):\n",
        "    self.features_type = features_type\n",
        "\n",
        "kernel = kernel_struct(0.2,'gaussian')\n",
        "features = features_struct('gray')\n",
        "\n",
        "if features.features_type == 'gray':\n",
        "  interp_factor = 0.075\n",
        "  cell_size = 1\n",
        "  kernel.sigma = 0.2\n",
        "elif features.features_type == 'hog':\n",
        "  interp_factor = 0.02\n",
        "  kernel.sigma = 0.5\n",
        "  cell_size = 4\n",
        "\n",
        "video_path = '/content/Girl/'\n",
        "img_files, pos, target_sz, ground_truth, video_path =  videoInfor(video_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xufr3KDLs6xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tracker(video_path,img_files,pos,target_sz,padding,kernel,lambda_reg,output_sigma_factor,\n",
        "        interp_factor,cell_size,features,ground_truth)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}